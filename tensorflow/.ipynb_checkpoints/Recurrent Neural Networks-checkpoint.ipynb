{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 14: Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cool Way to Visualize the Graph inside of Jupyter Notebook\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = b\"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script src=\"//cdnjs.cloudflare.com/ajax/libs/polymer/0.3.3/platform.js\"></script>\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"rnn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_path = './data/small_vocab_en'\n",
    "target_path = './data/small_vocab_fr'\n",
    "\n",
    "source_text = load_data(source_path)\n",
    "target_text = load_data(target_path)\n",
    "\n",
    "english_sentences = source_text.split('\\n')\n",
    "french_sentences = target_text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137861"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137861"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(french_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, array(['the', 'united', 'states', 'is', 'usually', 'chilly', 'during',\n",
       "        'july', ',', 'and', 'it', 'is', 'usually', 'freezing', 'in',\n",
       "        'november', '.'], dtype='<U8'), array(['california', 'is', 'usually', 'quiet', 'during', 'march', ',',\n",
       "        'and', 'it', 'is', 'usually', 'hot', 'in', 'june', '.'],\n",
       "       dtype='<U10'), array(['the', 'united', 'states', 'is', 'sometimes', 'mild', 'during',\n",
       "        'june', ',', 'and', 'it', 'is', 'cold', 'in', 'september', '.'],\n",
       "       dtype='<U9'), array(['your', 'least', 'liked', 'fruit', 'is', 'the', 'grape', ',',\n",
       "        'but', 'my', 'least', 'liked', 'is', 'the', 'apple', '.'],\n",
       "       dtype='<U5'), array(['his', 'favorite', 'fruit', 'is', 'the', 'orange', ',', 'but',\n",
       "        'my', 'favorite', 'is', 'the', 'grape', '.'], dtype='<U8'), array(['paris', 'is', 'relaxing', 'during', 'december', ',', 'but', 'it',\n",
       "        'is', 'usually', 'chilly', 'in', 'july', '.'], dtype='<U8'), array(['new', 'jersey', 'is', 'busy', 'during', 'spring', ',', 'and',\n",
       "        'it', 'is', 'never', 'hot', 'in', 'march', '.'], dtype='<U6'), array(['our', 'least', 'liked', 'fruit', 'is', 'the', 'lemon', ',', 'but',\n",
       "        'my', 'least', 'liked', 'is', 'the', 'grape', '.'], dtype='<U5'), array(['the', 'united', 'states', 'is', 'sometimes', 'busy', 'during',\n",
       "        'january', ',', 'and', 'it', 'is', 'sometimes', 'warm', 'in',\n",
       "        'november', '.'], dtype='<U9'), array(['the', 'lime', 'is', 'her', 'least', 'liked', 'fruit', ',', 'but',\n",
       "        'the', 'banana', 'is', 'my', 'least', 'liked', '.'], dtype='<U6'), array(['he', 'saw', 'a', 'old', 'yellow', 'truck', '.'], dtype='<U6'), array(['india', 'is', 'rainy', 'during', 'june', ',', 'and', 'it', 'is',\n",
       "        'sometimes', 'warm', 'in', 'november', '.'], dtype='<U9'), array(['that', 'cat', 'was', 'my', 'most', 'loved', 'animal', '.'],\n",
       "       dtype='<U6'), array(['he', 'dislikes', 'grapefruit', ',', 'limes', ',', 'and', 'lemons',\n",
       "        '.'], dtype='<U10'), array(['her', 'least', 'liked', 'fruit', 'is', 'the', 'lemon', ',', 'but',\n",
       "        'his', 'least', 'liked', 'is', 'the', 'grapefruit', '.'],\n",
       "       dtype='<U10'), array(['california', 'is', 'never', 'cold', 'during', 'february', ',',\n",
       "        'but', 'it', 'is', 'sometimes', 'freezing', 'in', 'june', '.'],\n",
       "       dtype='<U10'), array(['china', 'is', 'usually', 'pleasant', 'during', 'autumn', ',',\n",
       "        'and', 'it', 'is', 'usually', 'quiet', 'in', 'october', '.'],\n",
       "       dtype='<U8'), array(['paris', 'is', 'never', 'freezing', 'during', 'november', ',',\n",
       "        'but', 'it', 'is', 'wonderful', 'in', 'october', '.'], dtype='<U9'), array(['the', 'united', 'states', 'is', 'never', 'rainy', 'during',\n",
       "        'january', ',', 'but', 'it', 'is', 'sometimes', 'mild', 'in',\n",
       "        'october', '.'], dtype='<U9'), array(['china', 'is', 'usually', 'pleasant', 'during', 'november', ',',\n",
       "        'and', 'it', 'is', 'never', 'quiet', 'in', 'october', '.'],\n",
       "       dtype='<U8'), array(['the', 'united', 'states', 'is', 'never', 'nice', 'during',\n",
       "        'february', ',', 'but', 'it', 'is', 'sometimes', 'pleasant', 'in',\n",
       "        'april', '.'], dtype='<U9'), array(['india', 'is', 'never', 'busy', 'during', 'autumn', ',', 'and',\n",
       "        'it', 'is', 'mild', 'in', 'spring', '.'], dtype='<U6'), array(['paris', 'is', 'mild', 'during', 'summer', ',', 'but', 'it', 'is',\n",
       "        'usually', 'busy', 'in', 'april', '.'], dtype='<U7'), array(['france', 'is', 'never', 'cold', 'during', 'september', ',', 'and',\n",
       "        'it', 'is', 'snowy', 'in', 'october', '.'], dtype='<U9'), array(['california', 'is', 'never', 'cold', 'during', 'may', ',', 'and',\n",
       "        'it', 'is', 'sometimes', 'chilly', 'in', 'march', '.'],\n",
       "       dtype='<U10'), array(['he', 'dislikes', 'lemons', ',', 'grapes', ',', 'and', 'mangoes.'],\n",
       "       dtype='<U8'), array(['their', 'favorite', 'fruit', 'is', 'the', 'mango', ',', 'but',\n",
       "        'our', 'favorite', 'is', 'the', 'pear', '.'], dtype='<U8'), array(['france', 'is', 'sometimes', 'quiet', 'during', 'may', ',', 'and',\n",
       "        'it', 'is', 'never', 'chilly', 'in', 'august', '.'], dtype='<U9'), array(['paris', 'is', 'never', 'pleasant', 'during', 'september', ',',\n",
       "        'and', 'it', 'is', 'beautiful', 'in', 'autumn', '.'], dtype='<U9'), array(['he', 'dislikes', 'apples', ',', 'peaches', ',', 'and', 'grapes',\n",
       "        '.'], dtype='<U8'), array(['california', 'is', 'usually', 'freezing', 'during', 'december',\n",
       "        ',', 'and', 'it', 'is', 'busy', 'in', 'april', '.'], dtype='<U10'), array(['your', 'most', 'feared', 'animal', 'is', 'that', 'shark', '.'],\n",
       "       dtype='<U6'), array(['paris', 'is', 'usually', 'wet', 'during', 'august', ',', 'and',\n",
       "        'it', 'is', 'never', 'dry', 'in', 'november', '.'], dtype='<U8'), array(['paris', 'is', 'usually', 'beautiful', 'during', 'september', ',',\n",
       "        'and', 'it', 'is', 'usually', 'snowy', 'in', 'november', '.'],\n",
       "       dtype='<U9'), array(['the', 'united', 'states', 'is', 'never', 'wet', 'during',\n",
       "        'january', ',', 'but', 'it', 'is', 'usually', 'hot', 'in',\n",
       "        'october', '.'], dtype='<U7'), array(['we', 'like', 'oranges', ',', 'mangoes', ',', 'and', 'grapes', '.'],\n",
       "       dtype='<U7'), array(['they', 'like', 'pears', ',', 'apples', ',', 'and', 'mangoes', '.'],\n",
       "       dtype='<U7'), array(['she', 'dislikes', 'that', 'little', 'red', 'truck', '.'],\n",
       "       dtype='<U8'), array(['the', 'grapefruit', 'is', 'my', 'most', 'loved', 'fruit', ',',\n",
       "        'but', 'the', 'banana', 'is', 'her', 'most', 'loved', '.'],\n",
       "       dtype='<U10'), array(['france', 'is', 'snowy', 'during', 'may', ',', 'and', 'it', 'is',\n",
       "        'never', 'busy', 'in', 'autumn', '.'], dtype='<U6'), array(['china', 'is', 'usually', 'mild', 'during', 'winter', ',', 'but',\n",
       "        'it', 'is', 'never', 'busy', 'in', 'february', '.'], dtype='<U8'), array(['china', 'is', 'never', 'nice', 'during', 'july', ',', 'but', 'it',\n",
       "        'is', 'usually', 'snowy', 'in', 'spring', '.'], dtype='<U7'), array(['california', 'is', 'busy', 'during', 'november', ',', 'but', 'it',\n",
       "        'is', 'rainy', 'in', 'autumn', '.'], dtype='<U10'), array(['china', 'is', 'warm', 'during', 'spring', ',', 'and', 'it', 'is',\n",
       "        'sometimes', 'cold', 'in', 'february', '.'], dtype='<U9'), array(['california', 'is', 'usually', 'beautiful', 'during', 'winter',\n",
       "        ',', 'but', 'it', 'is', 'never', 'busy', 'in', 'february', '.'],\n",
       "       dtype='<U10'), array(['france', 'is', 'wonderful', 'during', 'november', ',', 'but',\n",
       "        'it', 'is', 'sometimes', 'hot', 'in', 'september', '.'],\n",
       "       dtype='<U9'), array(['india', 'is', 'usually', 'pleasant', 'during', 'november', ',',\n",
       "        'but', 'it', 'is', 'never', 'relaxing', 'in', 'july', '.'],\n",
       "       dtype='<U8'), array(['the', 'united', 'states', 'is', 'never', 'freezing', 'during',\n",
       "        'autumn', ',', 'but', 'it', 'is', 'never', 'busy', 'in', 'june',\n",
       "        '.'], dtype='<U8'), array(['paris', 'is', 'sometimes', 'warm', 'during', 'june', ',', 'but',\n",
       "        'it', 'is', 'usually', 'hot', 'in', 'july', '.'], dtype='<U9')]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smol_english = english_sentences[:50]\n",
    "smol_french = french_sentences[:50]\n",
    "\n",
    "x_train = [0] * 50\n",
    "y_pred = [0] * 50\n",
    "\n",
    "for i in range(1, len(x_train)):\n",
    "    x_train[i] = np.array(smol_english[i].split(' '))\n",
    "    y_pred[i] = np.array(smol_french[i].split(' '))\n",
    "    \n",
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Simple Encoder-Decoder Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "n_neurons = 200\n",
    "n_layers = 3\n",
    "num_encoder_symbols = 20000\n",
    "num_decoder_symbols = 20000\n",
    "embedding_size = 150\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, n_steps]) # English sentences\n",
    "Y = tf.placeholder(tf.int32, [None, n_steps]) # French translations\n",
    "W = tf.placeholder(tf.float32, [None, n_steps - 1, 1])\n",
    "Y_input = Y[:, :-1]\n",
    "Y_target = Y[:, 1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**X:**  Tensor(\"Placeholder:0\", shape=(?, 50), dtype=int32)\n",
    "\n",
    "**Y:**  Tensor(\"Placeholder_1:0\", shape=(?, 50), dtype=int32)\n",
    "\n",
    "**W:**  Tensor(\"Placeholder_2:0\", shape=(?, 49, 1), dtype=float32)\n",
    "\n",
    "**Y_input:**  Tensor(\"strided_slice:0\", shape=(?, 49), dtype=int32)\n",
    "\n",
    "**Y_target:**  Tensor(\"strided_slice_1:0\", shape=(?, 49), dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  Tensor(\"Placeholder:0\", shape=(?, 50), dtype=int32)\n",
      "Y:  Tensor(\"Placeholder_1:0\", shape=(?, 50), dtype=int32)\n",
      "W:  Tensor(\"Placeholder_2:0\", shape=(?, 49, 1), dtype=float32)\n",
      "Y_input:  Tensor(\"strided_slice:0\", shape=(?, 49), dtype=int32)\n",
      "Y_target:  Tensor(\"strided_slice_1:0\", shape=(?, 49), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print('X: ', X)\n",
    "print('Y: ', Y)\n",
    "print('W: ', W)\n",
    "print('Y_input: ', Y_input)\n",
    "print('Y_target: ', Y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.unstack(tf.transpose(X)) # list of 1D tensors\n",
    "decoder_inputs = tf.unstack(tf.transpose(Y_input)) # list of 1D tensors\n",
    "\n",
    "lstm_cells = [tf.nn.rnn_cell.BasicLSTMCell(num_units=n_neurons)\n",
    "              for layer in range(n_layers)]\n",
    "cell = tf.nn.rnn_cell.MultiRNNCell(lstm_cells)\n",
    "\n",
    "output_seqs, states = tf.contrib.legacy_seq2seq.embedding_rnn_seq2seq(\n",
    "    encoder_inputs,\n",
    "    decoder_inputs,\n",
    "    cell,\n",
    "    num_encoder_symbols,\n",
    "    num_decoder_symbols,\n",
    "    embedding_size)\n",
    "\n",
    "logits = tf.transpose(tf.unstack(output_seqs), perm=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_flat = tf.reshape(logits, [-1, num_decoder_symbols])\n",
    "Y_target_flat = tf.reshape(Y_target, [-1])\n",
    "W_flat = tf.reshape(W, [-1])\n",
    "xentropy = W_flat * tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y_target_flat, logits=logits_flat)\n",
    "loss = tf.reduce_mean(xentropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-4e7e981cefd0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0minit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     for step in range(n_steps):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1091\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1092\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1093\u001b[1;33m             \u001b[0mnp_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m     \"\"\"\n\u001b[1;32m--> 492\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    \n",
    "    sess.run(y_pred, feed_dict={X: x_train})\n",
    "    \n",
    "#     for step in range(n_steps):\n",
    "#         print(\"\\rIteration: {}\".format(step), end=\"\\t\")\n",
    "#         feed_dict = {}\n",
    "#     y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
